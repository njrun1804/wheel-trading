"""
Error Monitoring and Analysis System

Provides real-time error monitoring, pattern detection, and predictive
failure analysis for the Bolt system.
"""

import asyncio
import contextlib
import logging
import statistics
import threading
import time
from collections import defaultdict, deque
from collections.abc import Callable
from dataclasses import dataclass, field
from enum import Enum
from typing import Any

from .exceptions import BoltException, ErrorCategory, ErrorSeverity


class AlertLevel(Enum):
    """Alert levels for error monitoring."""

    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class ErrorPattern:
    """Represents a detected error pattern."""

    pattern_id: str
    error_codes: set[str]
    frequency: int
    time_window: float
    severity: ErrorSeverity
    category: ErrorCategory
    description: str
    confidence: float = 0.0
    first_seen: float = field(default_factory=time.time)
    last_seen: float = field(default_factory=time.time)


@dataclass
class ErrorAlert:
    """Alert generated by error monitoring."""

    alert_id: str
    level: AlertLevel
    message: str
    error_pattern: ErrorPattern | None = None
    error_count: int = 0
    time_window: float = 0.0
    timestamp: float = field(default_factory=time.time)
    metadata: dict[str, Any] = field(default_factory=dict)


@dataclass
class ErrorMetrics:
    """Error metrics for analysis."""

    total_errors: int = 0
    errors_by_category: dict[str, int] = field(default_factory=lambda: defaultdict(int))
    errors_by_severity: dict[str, int] = field(default_factory=lambda: defaultdict(int))
    errors_by_hour: dict[int, int] = field(default_factory=lambda: defaultdict(int))
    error_rate_per_minute: float = 0.0
    error_rate_trend: str = "stable"  # "increasing", "decreasing", "stable"
    mean_time_between_errors: float = 0.0
    most_common_errors: list[tuple[str, int]] = field(default_factory=list)


class ErrorMonitor:
    """Real-time error monitoring and analysis."""

    def __init__(
        self,
        max_error_history: int = 10000,
        pattern_detection_window: float = 300.0,  # 5 minutes
        alert_cooldown: float = 60.0,  # 1 minute between similar alerts
    ):
        self.logger = logging.getLogger(f"{__name__}.ErrorMonitor")

        # Configuration
        self.max_error_history = max_error_history
        self.pattern_detection_window = pattern_detection_window
        self.alert_cooldown = alert_cooldown

        # Error tracking
        self.error_history: deque = deque(maxlen=max_error_history)
        self.error_counts: dict[str, int] = defaultdict(int)
        self.error_timestamps: dict[str, list[float]] = defaultdict(list)

        # Pattern detection
        self.detected_patterns: dict[str, ErrorPattern] = {}
        self.pattern_thresholds = {
            "burst_threshold": 5,  # errors in short time
            "sustained_threshold": 10,  # errors over longer period
            "frequency_threshold": 3,  # similar errors
        }

        # Alerting
        self.alerts: deque = deque(maxlen=1000)
        self.alert_handlers: list[Callable[[ErrorAlert], None]] = []
        self.last_alert_times: dict[str, float] = {}

        # Monitoring state
        self._monitoring = False
        self._monitor_task: asyncio.Task | None = None
        self._lock = threading.RLock()

        # Metrics
        self.current_metrics = ErrorMetrics()
        self.metrics_history: list[tuple[float, ErrorMetrics]] = []

        # Predictive analysis
        self.failure_predictors: list[Callable[[list[BoltException]], float]] = []
        self._setup_default_predictors()

    def _setup_default_predictors(self):
        """Setup default failure prediction algorithms."""

        def memory_failure_predictor(recent_errors: list[BoltException]) -> float:
            """Predict memory-related failures."""
            memory_errors = [
                e
                for e in recent_errors
                if e.category == ErrorCategory.RESOURCE and "memory" in str(e).lower()
            ]

            if len(memory_errors) > 3:
                return min(0.8, len(memory_errors) * 0.15)
            return 0.0

        def agent_failure_predictor(recent_errors: list[BoltException]) -> float:
            """Predict agent-related failures."""
            agent_errors = [
                e for e in recent_errors if e.category == ErrorCategory.AGENT
            ]

            # Check for increasing error rate
            if len(agent_errors) > 2:
                times = [e.context.timestamp for e in agent_errors]
                times.sort()

                # Check if errors are accelerating
                if len(times) >= 3:
                    intervals = [times[i + 1] - times[i] for i in range(len(times) - 1)]
                    if len(intervals) >= 2 and intervals[-1] < intervals[0] * 0.5:
                        return 0.6  # Accelerating error rate

            return min(0.5, len(agent_errors) * 0.1)

        def system_cascade_predictor(recent_errors: list[BoltException]) -> float:
            """Predict cascading system failures."""
            categories = set(e.category for e in recent_errors)

            # Multiple error categories suggest system-wide issues
            if len(categories) >= 3:
                return min(0.7, len(categories) * 0.15)

            # High severity errors
            critical_errors = [
                e for e in recent_errors if e.severity == ErrorSeverity.CRITICAL
            ]
            if len(critical_errors) > 1:
                return min(0.9, len(critical_errors) * 0.3)

            return 0.0

        self.failure_predictors.extend(
            [
                memory_failure_predictor,
                agent_failure_predictor,
                system_cascade_predictor,
            ]
        )

    def record_error(self, error: BoltException, context: dict[str, Any] | None = None):
        """Record an error for monitoring and analysis."""

        with self._lock:
            current_time = time.time()
            error_key = f"{error.category.value}:{error.error_code}"

            # Add to history
            error_record = {
                "timestamp": current_time,
                "error": error,
                "context": context or {},
                "error_key": error_key,
            }
            self.error_history.append(error_record)

            # Update counts
            self.error_counts[error_key] += 1
            self.error_timestamps[error_key].append(current_time)

            # Trim old timestamps
            cutoff_time = current_time - self.pattern_detection_window
            self.error_timestamps[error_key] = [
                ts for ts in self.error_timestamps[error_key] if ts > cutoff_time
            ]

            # Update metrics
            self._update_metrics()

            # Check for patterns
            asyncio.create_task(self._check_error_patterns(error_record))

            self.logger.debug(f"Recorded error: {error_key}")

    def _update_metrics(self):
        """Update current error metrics."""
        current_time = time.time()
        cutoff_time = current_time - 3600  # Last hour

        # Filter recent errors
        recent_errors = [
            record for record in self.error_history if record["timestamp"] > cutoff_time
        ]

        # Calculate metrics
        self.current_metrics.total_errors = len(recent_errors)

        # Reset counters
        self.current_metrics.errors_by_category.clear()
        self.current_metrics.errors_by_severity.clear()
        self.current_metrics.errors_by_hour.clear()

        # Count by category and severity
        for record in recent_errors:
            error = record["error"]
            category = error.category.value
            severity = error.severity.value
            hour = int((record["timestamp"] % 86400) // 3600)

            self.current_metrics.errors_by_category[category] += 1
            self.current_metrics.errors_by_severity[severity] += 1
            self.current_metrics.errors_by_hour[hour] += 1

        # Calculate error rate (per minute)
        if recent_errors:
            time_span = current_time - recent_errors[0]["timestamp"]
            if time_span > 0:
                self.current_metrics.error_rate_per_minute = len(recent_errors) / (
                    time_span / 60
                )

        # Calculate mean time between errors
        if len(recent_errors) > 1:
            timestamps = [r["timestamp"] for r in recent_errors]
            timestamps.sort()
            intervals = [
                timestamps[i + 1] - timestamps[i] for i in range(len(timestamps) - 1)
            ]
            self.current_metrics.mean_time_between_errors = statistics.mean(intervals)

        # Most common errors
        error_counts = defaultdict(int)
        for record in recent_errors:
            error_counts[record["error_key"]] += 1

        self.current_metrics.most_common_errors = sorted(
            error_counts.items(), key=lambda x: x[1], reverse=True
        )[:10]

        # Determine trend
        self._calculate_error_trend()

    def _calculate_error_trend(self):
        """Calculate error rate trend."""
        if len(self.metrics_history) < 2:
            self.current_metrics.error_rate_trend = "stable"
            return

        # Compare current rate with recent history
        recent_rates = [
            metrics.error_rate_per_minute for _, metrics in self.metrics_history[-5:]
        ]
        current_rate = self.current_metrics.error_rate_per_minute

        if len(recent_rates) >= 3:
            avg_recent = statistics.mean(recent_rates)

            if current_rate > avg_recent * 1.5:
                self.current_metrics.error_rate_trend = "increasing"
            elif current_rate < avg_recent * 0.7:
                self.current_metrics.error_rate_trend = "decreasing"
            else:
                self.current_metrics.error_rate_trend = "stable"

    async def _check_error_patterns(self, error_record: dict[str, Any]):
        """Check for error patterns and generate alerts."""

        current_time = time.time()
        error = error_record["error"]
        error_key = error_record["error_key"]

        # Check for burst patterns (many errors in short time)
        recent_count = len(
            [
                ts
                for ts in self.error_timestamps[error_key]
                if ts > current_time - 60  # Last minute
            ]
        )

        if recent_count >= self.pattern_thresholds["burst_threshold"]:
            await self._generate_alert(
                AlertLevel.ERROR,
                f"Error burst detected: {recent_count} occurrences of {error_key} in 1 minute",
                error_count=recent_count,
                time_window=60.0,
                metadata={"error_key": error_key, "pattern": "burst"},
            )

        # Check for sustained patterns (consistent errors over time)
        sustained_count = len(
            [
                ts
                for ts in self.error_timestamps[error_key]
                if ts > current_time - self.pattern_detection_window
            ]
        )

        if sustained_count >= self.pattern_thresholds["sustained_threshold"]:
            await self._generate_alert(
                AlertLevel.WARNING,
                f"Sustained error pattern: {sustained_count} occurrences of {error_key} in {self.pattern_detection_window/60:.1f} minutes",
                error_count=sustained_count,
                time_window=self.pattern_detection_window,
                metadata={"error_key": error_key, "pattern": "sustained"},
            )

        # Check for critical errors
        if error.severity == ErrorSeverity.CRITICAL:
            await self._generate_alert(
                AlertLevel.CRITICAL,
                f"Critical error detected: {error.message}",
                error_count=1,
                metadata={
                    "error_code": error.error_code,
                    "category": error.category.value,
                },
            )

        # Check for cascading failures (multiple error categories)
        recent_errors = [
            record["error"]
            for record in self.error_history
            if record["timestamp"] > current_time - 300  # Last 5 minutes
        ]

        error_categories = set(e.category for e in recent_errors)
        if len(error_categories) >= 3:
            await self._generate_alert(
                AlertLevel.ERROR,
                f"Potential cascading failure: {len(error_categories)} error categories in 5 minutes",
                error_count=len(recent_errors),
                time_window=300.0,
                metadata={"categories": [cat.value for cat in error_categories]},
            )

    async def _generate_alert(
        self,
        level: AlertLevel,
        message: str,
        error_count: int = 0,
        time_window: float = 0.0,
        metadata: dict[str, Any] | None = None,
    ):
        """Generate an alert."""

        # Check cooldown
        alert_key = f"{level.value}:{hash(message)}"
        current_time = time.time()

        if alert_key in self.last_alert_times:
            if current_time - self.last_alert_times[alert_key] < self.alert_cooldown:
                return  # Skip duplicate alert during cooldown

        self.last_alert_times[alert_key] = current_time

        # Create alert
        alert = ErrorAlert(
            alert_id=f"alert_{int(current_time)}_{hash(message) % 10000}",
            level=level,
            message=message,
            error_count=error_count,
            time_window=time_window,
            metadata=metadata or {},
        )

        self.alerts.append(alert)

        # Log alert
        log_method = {
            AlertLevel.INFO: self.logger.info,
            AlertLevel.WARNING: self.logger.warning,
            AlertLevel.ERROR: self.logger.error,
            AlertLevel.CRITICAL: self.logger.critical,
        }.get(level, self.logger.info)

        log_method(f"ALERT [{level.value.upper()}]: {message}")

        # Notify handlers
        for handler in self.alert_handlers:
            try:
                if asyncio.iscoroutinefunction(handler):
                    await handler(alert)
                else:
                    handler(alert)
            except Exception as e:
                self.logger.error(f"Alert handler failed: {e}")

    def add_alert_handler(self, handler: Callable[[ErrorAlert], None]):
        """Add an alert handler."""
        self.alert_handlers.append(handler)

    def predict_failure_probability(self) -> dict[str, float]:
        """Predict probability of different types of failures."""

        # Get recent errors for analysis
        current_time = time.time()
        recent_errors = [
            record["error"]
            for record in self.error_history
            if record["timestamp"] > current_time - 1800  # Last 30 minutes
        ]

        predictions = {}

        # Run all predictors
        for i, predictor in enumerate(self.failure_predictors):
            try:
                prediction = predictor(recent_errors)
                predictor_name = (
                    predictor.__name__
                    if hasattr(predictor, "__name__")
                    else f"predictor_{i}"
                )
                predictions[predictor_name] = max(0.0, min(1.0, prediction))
            except Exception as e:
                self.logger.error(f"Failure predictor failed: {e}")

        # Overall system health prediction
        if predictions:
            max_prediction = max(predictions.values())
            avg_prediction = sum(predictions.values()) / len(predictions)

            predictions["overall_failure_risk"] = (max_prediction + avg_prediction) / 2
        else:
            predictions["overall_failure_risk"] = 0.0

        return predictions

    async def start_monitoring(self):
        """Start continuous error monitoring."""
        if self._monitoring:
            return

        self._monitoring = True
        self.logger.info("Started error monitoring")
        self._monitor_task = asyncio.create_task(self._monitoring_loop())

    async def stop_monitoring(self):
        """Stop error monitoring."""
        self._monitoring = False

        if self._monitor_task:
            self._monitor_task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await self._monitor_task
            self._monitor_task = None

        self.logger.info("Stopped error monitoring")

    async def _monitoring_loop(self):
        """Main monitoring loop."""
        try:
            while self._monitoring:
                # Update metrics
                with self._lock:
                    self._update_metrics()

                    # Store metrics history
                    current_time = time.time()
                    self.metrics_history.append((current_time, self.current_metrics))

                    # Trim history (keep last 24 hours worth)
                    cutoff_time = current_time - 86400
                    self.metrics_history = [
                        (ts, metrics)
                        for ts, metrics in self.metrics_history
                        if ts > cutoff_time
                    ]

                # Check for system-wide issues
                await self._check_system_health()

                # Predictive analysis
                predictions = self.predict_failure_probability()
                high_risk_predictions = {
                    name: prob for name, prob in predictions.items() if prob > 0.7
                }

                if high_risk_predictions:
                    await self._generate_alert(
                        AlertLevel.WARNING,
                        f"High failure risk detected: {', '.join(f'{name}={prob:.1%}' for name, prob in high_risk_predictions.items())}",
                        metadata={"predictions": predictions},
                    )

                await asyncio.sleep(30)  # Check every 30 seconds

        except asyncio.CancelledError:
            pass
        except Exception as e:
            self.logger.error(f"Monitoring loop error: {e}", exc_info=True)

    async def _check_system_health(self):
        """Check overall system health based on error patterns."""

        time.time()

        # Check error rate
        if self.current_metrics.error_rate_per_minute > 10:
            await self._generate_alert(
                AlertLevel.ERROR,
                f"High error rate: {self.current_metrics.error_rate_per_minute:.1f} errors/minute",
                metadata={"error_rate": self.current_metrics.error_rate_per_minute},
            )

        # Check error trend
        if self.current_metrics.error_rate_trend == "increasing":
            await self._generate_alert(
                AlertLevel.WARNING,
                "Error rate is increasing",
                metadata={"trend": self.current_metrics.error_rate_trend},
            )

        # Check for critical error accumulation
        critical_errors = sum(
            count
            for severity, count in self.current_metrics.errors_by_severity.items()
            if severity == "critical"
        )

        if critical_errors > 5:
            await self._generate_alert(
                AlertLevel.CRITICAL,
                f"Multiple critical errors: {critical_errors} in last hour",
                error_count=critical_errors,
                metadata={"critical_error_count": critical_errors},
            )

    def get_error_summary(self) -> dict[str, Any]:
        """Get comprehensive error summary."""

        with self._lock:
            time.time()

            # Recent alerts
            recent_alerts = [
                {
                    "level": alert.level.value,
                    "message": alert.message,
                    "timestamp": alert.timestamp,
                    "error_count": alert.error_count,
                }
                for alert in list(self.alerts)[-10:]
            ]

            return {
                "monitoring_active": self._monitoring,
                "total_errors_tracked": len(self.error_history),
                "current_metrics": {
                    "total_errors": self.current_metrics.total_errors,
                    "error_rate_per_minute": self.current_metrics.error_rate_per_minute,
                    "error_rate_trend": self.current_metrics.error_rate_trend,
                    "mean_time_between_errors": self.current_metrics.mean_time_between_errors,
                    "errors_by_category": dict(self.current_metrics.errors_by_category),
                    "errors_by_severity": dict(self.current_metrics.errors_by_severity),
                    "most_common_errors": self.current_metrics.most_common_errors[:5],
                },
                "recent_alerts": recent_alerts,
                "failure_predictions": self.predict_failure_probability(),
                "patterns_detected": len(self.detected_patterns),
                "alert_handlers_count": len(self.alert_handlers),
            }

    def clear_history(self, older_than_hours: int = 24):
        """Clear old error history."""

        cutoff_time = time.time() - (older_than_hours * 3600)

        with self._lock:
            # Clear error history
            self.error_history = deque(
                (
                    record
                    for record in self.error_history
                    if record["timestamp"] > cutoff_time
                ),
                maxlen=self.max_error_history,
            )

            # Clear timestamp tracking
            for error_key in list(self.error_timestamps.keys()):
                self.error_timestamps[error_key] = [
                    ts for ts in self.error_timestamps[error_key] if ts > cutoff_time
                ]

                if not self.error_timestamps[error_key]:
                    del self.error_timestamps[error_key]

            # Clear old alerts
            self.alerts = deque(
                (alert for alert in self.alerts if alert.timestamp > cutoff_time),
                maxlen=1000,
            )

            self.logger.info(
                f"Cleared error history older than {older_than_hours} hours"
            )


# Global error monitor
_error_monitor: ErrorMonitor | None = None


def get_error_monitor() -> ErrorMonitor:
    """Get or create the global error monitor."""
    global _error_monitor
    if _error_monitor is None:
        _error_monitor = ErrorMonitor()
    return _error_monitor
