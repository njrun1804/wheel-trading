#!/usr/bin/env python3
"""Fixed orchestrator launcher with all imports working."""

import asyncio
import os
import sys
import time
from pathlib import Path

# Configure for optimal performance
os.environ["USE_MCP_SERVERS"] = "0"  # Direct I/O only to avoid MCP issues
os.environ["USE_GPU_ACCELERATION"] = "true"
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
os.environ["METAL_DEVICE_WRAPPER_TYPE"] = "1"

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))


async def main():
    """Launch orchestrator with hardware acceleration."""

    # Import the fixed orchestrator
    from unity_wheel.orchestrator.orchestrator_consolidated import (
        ConsolidatedOrchestrator,
        StrategyType,
    )

    # Get command
    if len(sys.argv) > 1:
        command = " ".join(sys.argv[1:])
    else:
        print("üöÄ Unity Wheel Orchestrator - Hardware Accelerated")
        print("=" * 50)
        print("\nUsage: ./launch_orchestrator_fixed.py '<command>'")
        print("\nExamples:")
        print("  ./launch_orchestrator_fixed.py 'analyze trading strategies'")
        print("  ./launch_orchestrator_fixed.py 'optimize wheel strategy code'")
        print("  ./launch_orchestrator_fixed.py 'list all Python files'")
        return

    print("\nüöÄ Launching orchestrator...")
    print(f"üìã Command: {command}")
    print("-" * 70)

    # Create orchestrator
    orchestrator = ConsolidatedOrchestrator(".")

    # Initialize
    start_init = time.time()
    await orchestrator.initialize()
    print(f"‚úÖ Initialized in {time.time() - start_init:.2f}s")

    # Auto-select strategy based on command
    if "optimize" in command.lower() or "performance" in command.lower():
        strategy = StrategyType.GPU_ACCELERATED
    elif "trading" in command.lower():
        strategy = StrategyType.TRADING_OPTIMIZED
    elif "quick" in command.lower() or "list" in command.lower():
        strategy = StrategyType.FAST
    else:
        strategy = StrategyType.ENHANCED

    print(f"üìä Using strategy: {strategy.value}")

    # Execute
    start_exec = time.time()
    try:
        result = await orchestrator.execute(command, strategy)

        # Display results
        print(f"\n‚úÖ Execution completed in {time.time() - start_exec:.2f}s")

        # Show phase results
        if "phases" in result:
            print("\nüìà Phase Results:")
            for phase_name, phase_data in result["phases"].items():
                if isinstance(phase_data, dict):
                    print(f"\n{phase_name.upper()}:")
                    for key, value in phase_data.items():
                        if key != "duration_ms":
                            print(f"  ‚Ä¢ {key}: {value}")
                    if "duration_ms" in phase_data:
                        print(f"  ‚è±Ô∏è  Duration: {phase_data['duration_ms']:.1f}ms")

        # Show performance
        if "performance" in result:
            perf = result["performance"]
            print("\n‚ö° Performance:")
            print(f"  ‚Ä¢ Total time: {perf.get('total_time_ms', 0):.1f}ms")
            print(f"  ‚Ä¢ Success: {perf.get('success', False)}")
            if "memory_peak_mb" in perf:
                print(f"  ‚Ä¢ Memory peak: {perf['memory_peak_mb']:.1f}MB")

        # Show any errors
        if "error" in result:
            print(f"\n‚ùå Error: {result['error']}")

    except Exception as e:
        print(f"\n‚ùå Execution failed: {e}")
        import traceback

        traceback.print_exc()

    # Shutdown
    await orchestrator.shutdown()

    # Hardware status
    print("\n" + "-" * 70)
    print("üíª Hardware Status:")

    try:
        import psutil

        print(f"  ‚Ä¢ CPU cores: {psutil.cpu_count()}")
        print(f"  ‚Ä¢ CPU usage: {psutil.cpu_percent(interval=0.5):.1f}%")

        mem = psutil.virtual_memory()
        print(f"  ‚Ä¢ Memory: {mem.used/1024**3:.1f}GB / {mem.total/1024**3:.1f}GB")
    except (ImportError, AttributeError, OSError) as e:
        print(f"  ‚Ä¢ System info: Unable to get system status ({e})")

    try:
        import torch

        if torch.backends.mps.is_available():
            print("  ‚Ä¢ GPU: Metal Performance Shaders ‚úÖ")
        else:
            print("  ‚Ä¢ GPU: Not available ‚ùå")
    except (ImportError, AttributeError, RuntimeError) as e:
        print(f"  ‚Ä¢ GPU: PyTorch not available ({e})")

    print("\n‚ú® Done!")


if __name__ == "__main__":
    asyncio.run(main())
